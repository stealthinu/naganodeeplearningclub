{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "backprop1.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "cells": [
  {
   "metadata": {
    "id": "7gdzAyFdI9fZ",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "**2.4** バックプロパゲーションの実装"
   ]
  },
  {
   "metadata": {
    "id": "3OYrEn3hI9fa",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "**2.4.1** クラス化"
   ]
  },
  {
   "metadata": {
    "id": "7w4L7RcuI9fa",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size                           # 入力数\n",
    "        self.output_size = output_size                         # ニューロン数と同じ\n",
    "        self.w = (np.random.rand(output_size, input_size) - 0.5) * 0.1 # ニューロンごとに入力と同数の足がある分の重み\n",
    "        self.b = (np.random.rand(output_size) - 0.5) * 0.2             # ニューロンごとのしきい値\n",
    "    \n",
    "    def h(self, x):\n",
    "        return sigmoid(x)\n",
    "    \n",
    "    def dh(self, x):\n",
    "        return dsigmoid(x)\n",
    "    \n",
    "    def output_neuron(self, W, b, X):\n",
    "        s = np.sum(W*X)\n",
    "        y = self.h(s - b)\n",
    "        return y\n",
    "    \n",
    "    def train_neuron(self, W, b, X, T):\n",
    "        O = self.output_neuron(W, b, X)\n",
    "        d = -alpha*(T - O)*self.dh(O);\n",
    "        W -= d*X\n",
    "        return\n",
    "    \n",
    "    def output_layer(self, x):\n",
    "        y = np.zeros(self.output_size)\n",
    "        for i in range(self.output_size):\n",
    "            y[i] = self.output_neuron(self.w[i], self.b[i], x)\n",
    "        return y\n",
    "\n",
    "    def train_layer(self, x, t):\n",
    "        for i in range(self.output_size):\n",
    "            self.train_neuron(self.w[i], self.b[i], x, t[i])\n",
    "        return"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "G2wRd0E6m0Yo",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "def calc_square_error(O, T):\n",
    "    return np.sum(np.square(O - T))\n",
    "\n",
    "def train_mnist(train_count):\n",
    "    images, labels = mnist.train.next_batch(train_count)\n",
    "    square_error = 0.0\n",
    "    for i in range(len(images)):\n",
    "        x = images[i]\n",
    "        t = labels[i]\n",
    "        y = layer1.output_layer(x)\n",
    "        layer1.train_layer(x, t)\n",
    "        square_error += calc_square_error(y, t)\n",
    "    print(square_error/train_count/10) # 1ニューロンあたりの誤差\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "w6qItYy4I9fd",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "layer1 = Layer(784, 10)\n",
    "alpha = 0.1\n",
    "train_mnist(1)   "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "rYTQFV_SI9ff",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "train_mnist(1000)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "pSWoi9coI9fh",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "def test_mnist():\n",
    "    images, labels = mnist.test.next_batch(1)\n",
    "    x = images[0]\n",
    "    t = labels[0]\n",
    "    y = layer1.output_layer(x)\n",
    "    print(t)\n",
    "    print(y)\n",
    "    print(np.argmax(y))\n",
    "    # イメージ表示\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    plt.imshow(x.reshape((28,28)), vmin=0, vmax=1,cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "ixhX1JexI9fj",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "test_mnist()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "8ezJRHfEI9fm",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "**2.4.1** ニューロンごとの誤差の元を保持する。"
   ]
  },
  {
   "metadata": {
    "id": "tDRDhcWrI9fn",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size                           # 入力数\n",
    "        self.output_size = output_size                         # ニューロン数と同じ\n",
    "        self.neurons_W = (np.random.rand(output_size, input_size) - 0.5) * 0.1 # ニューロンごとに入力と同数の足がある分の重み\n",
    "        self.neurons_b = (np.random.rand(output_size) - 0.5) * 0.2             # ニューロンごとのしきい値\n",
    "        self.neurons_d = np.zeros(output_size)                                 # ニューロンごとの誤差修正値\n",
    "    \n",
    "    def h(self, x):\n",
    "        return sigmoid(x)\n",
    "        #return tanh(x)\n",
    "        #return relu(x)\n",
    "    \n",
    "    def dh(self, y):\n",
    "        return dsigmoid(y)\n",
    "        #return dtanh(y)\n",
    "        #return drelu(y)\n",
    "    \n",
    "    def output_layer(self, X):\n",
    "        y = np.zeros(self.output_size)\n",
    "        for i in range(self.output_size):\n",
    "            # y = h(sum(W*X) - b)\n",
    "            y[i] = self.h(np.sum(self.neurons_W[i]*X) - self.neurons_b[i])\n",
    "        return y\n",
    "\n",
    "    def train_layer(self, X):\n",
    "        for i in range(self.output_size):\n",
    "            # W = W - (-alpha*d*X)\n",
    "            self.neurons_W[i] -= -alpha*self.neurons_d[i]*X\n",
    "        return\n",
    "    \n",
    "    # 出力層での自分自身の誤差修正値をセット\n",
    "    def backprop_layer_output(self, O, T):\n",
    "        # d = (T - O)*dh(O)\n",
    "        self.neurons_d = (T - O)*self.dh(O)\n",
    "        return\n",
    "\n",
    "    # 前のレイヤーへの誤差修正値を算出\n",
    "    def backprop_layer(self):\n",
    "        total_prev_D = np.zeros(self.input_size)\n",
    "        for i in range(self.output_size):\n",
    "            #total_prev_D += W*d\n",
    "            total_prev_D += self.neurons_W[i]*self.neurons_d[i]\n",
    "        return total_prev_D\n",
    "\n",
    "    # 後のレイヤーで計算された誤差修正値に出力値を掛けて自レイヤーに値をセット\n",
    "    def set_layer_d(self, D, O):\n",
    "        # d = D*dh(O)\n",
    "        self.neurons_d = D*self.dh(O)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "2c41SkXhI9fo",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "layer1 = Layer(784, 10)\n",
    "alpha = 0.01\n",
    "\n",
    "def train_mnist(train_count):\n",
    "    images, labels = mnist.train.next_batch(train_count)\n",
    "    square_error = 0.0\n",
    "    for i in range(len(images)):\n",
    "        X = images[i]\n",
    "        T = labels[i]\n",
    "        Y = layer1.output_layer(X)\n",
    "        layer1.backprop_layer_output(Y, T)\n",
    "        layer1.train_layer(X)\n",
    "        square_error += calc_square_error(Y, T)\n",
    "    print(square_error/train_count/10) # 1ニューロンあたりの誤差\n",
    "\n",
    "train_mnist(1)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "OC5v-9htI9ft",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "alpha = 0.01\n",
    "train_mnist(10000)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "8orqzQkmI9fv",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "# ３層ネットワーク 784x100x10\n",
    "layer1 = Layer(784, 100)\n",
    "layer2 = Layer(100, 10)\n",
    "alpha = 0.01\n",
    "mini_batch = 100\n",
    "epoch = 0\n",
    "epochs, dpns = [], []\n",
    "\n",
    "def output_backprop_mnist(X):\n",
    "    # 正方向でニューロンの出力\n",
    "    O1 = layer1.output_layer(X)\n",
    "    Y  = layer2.output_layer(O1)\n",
    "    return Y\n",
    "\n",
    "def train_backprop_mnist(train_count):\n",
    "    global layer1, layer2, epoch, epochs, dpns\n",
    "    for count in range(train_count):\n",
    "        images, labels = mnist.train.next_batch(mini_batch)\n",
    "        square_error = 0.0\n",
    "        for i in range(mini_batch):\n",
    "            X = images[i]\n",
    "            T = labels[i]\n",
    "            # 正方向でニューロンの出力\n",
    "            O1 = layer1.output_layer(X)\n",
    "            Y  = layer2.output_layer(O1)\n",
    "            # 逆伝搬で誤差修正値をニューロン毎に算出\n",
    "            layer2.backprop_layer_output(Y, T)\n",
    "            D1 = layer2.backprop_layer()\n",
    "            layer1.set_layer_d(D1, O1)\n",
    "            # 誤差修正値を使って学習\n",
    "            layer2.train_layer(O1)\n",
    "            layer1.train_layer(X)\n",
    "            # 二乗誤差算出\n",
    "            square_error += calc_square_error(Y, T)\n",
    "        epoch += mini_batch\n",
    "        dpn = square_error/mini_batch/10 # 1ニューロンあたりの誤差\n",
    "        epochs.append(epoch)\n",
    "        dpns.append(dpn)\n",
    "    print(\"epoch:\" + str(epoch) + \" d/neuron:\" + str(dpn))\n",
    "\n",
    "train_backprop_mnist(1)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "3SykJjpoI9fy",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "alpha = 0.01\n",
    "train_backprop_mnist(1000)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "qeQMqYFLI9f0",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(epochs, dpns)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "FE6DfplzI9f2",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "def test_backprop_mnist():\n",
    "    images, labels = mnist.test.next_batch(1)\n",
    "    X = images[0]\n",
    "    T = labels[0]\n",
    "    Y = output_backprop_mnist(X)\n",
    "    print(T)\n",
    "    print(Y)\n",
    "    print(np.argmax(Y))\n",
    "    # イメージ表示\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    plt.imshow(X.reshape((28,28)), vmin=0, vmax=1,cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "xiX-iIQ_I9f5",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "test_backprop_mnist()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "mQ60E5yLI9f8",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "def test_backprop_mnist_error():\n",
    "    test_count = 1000\n",
    "    images, labels = mnist.test.next_batch(test_count)\n",
    "    ng = 0\n",
    "    for j in range(len(images)):\n",
    "        X = images[j]\n",
    "        T = labels[j]\n",
    "        Y = output_backprop_mnist(X)\n",
    "        if np.argmax(T) != np.argmax(Y):\n",
    "            ng += 1\n",
    "            #print(\"T:\" + str(np.argmax(T)) + \" Y:\" + str(np.argmax(Y)) + \" NG!\")\n",
    "        #else:\n",
    "            #print(\"T:\" + str(np.argmax(T)) + \" Y:\" + str(np.argmax(Y)))\n",
    "    print(ng / test_count)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "gh3FB7dZI9f_",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "test_backprop_mnist_error()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "M_i8NnCZI9gB",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "ディープラーニングの技術を試す"
   ]
  },
  {
   "metadata": {
    "id": "6LbO5eTbI9gC",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "学習の高速化手法の変更（ローカルミニマム対策としても）\n",
    "- SGD (素の確率的勾配降下法）\n",
    "- Momentum\n",
    "- AdaGrad"
   ]
  },
  {
   "metadata": {
    "id": "pSBhEjTJI9gC",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "勾配消失問題への対応（活性化関数の変更）\n",
    "- sigmoid\n",
    "- tanh\n",
    "- ReLU"
   ]
  },
  {
   "metadata": {
    "id": "iTDQJ_veI9gD",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "def calc_square_error(O, T):\n",
    "    return np.sum(np.square(O - T))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y*(1 - y)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(y):\n",
    "    return 1 - np.square(np.tanh(y))\n",
    "\n",
    "def relu(x):\n",
    "    #return x if x > 0 else 0\n",
    "    return x * (x > 0)\n",
    "\n",
    "def drelu(y):\n",
    "    #return 1 if y > 0 else 0\n",
    "    return 1 * (y > 0)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "hr6Jj7fWI9gG",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size                           # 入力数\n",
    "        self.output_size = output_size                         # ニューロン数と同じ\n",
    "        self.neurons_W = (np.random.rand(output_size, input_size) - 0.5) * 0.1 # ニューロンごとに入力と同数の足がある分の重み\n",
    "        self.neurons_b = (np.random.rand(output_size) - 0.5) * 0.2             # ニューロンごとのしきい値\n",
    "        self.neurons_d = np.zeros(output_size)                                 # ニューロンごとの誤差修正値\n",
    "        self.neurons_P = np.zeros((output_size, input_size))                   # パラメータ更新の高速化用保持パラメータ\n",
    "\n",
    "    def h(self, x):\n",
    "        return sigmoid(x)\n",
    "        #return tanh(x)\n",
    "        #return relu(x)\n",
    "    \n",
    "    def dh(self, y):\n",
    "        return dsigmoid(y)\n",
    "        #return dtanh(y)\n",
    "        #return drelu(y)\n",
    "    \n",
    "    def dw(self, i, X):\n",
    "        #return self.sgd(i, X)\n",
    "        return self.momentum(i, X)\n",
    "        #return self.adagrad(i, X)\n",
    "    \n",
    "    def output_layer(self, X):\n",
    "        y = np.zeros(self.output_size)\n",
    "        for i in range(self.output_size):\n",
    "            # y = h(sum(W*X) - b)\n",
    "            y[i] = self.h(np.sum(self.neurons_W[i]*X) - self.neurons_b[i])\n",
    "        return y\n",
    "\n",
    "    def train_layer(self, X):\n",
    "        for i in range(self.output_size):\n",
    "            # W = W - (-alpha*d*X)\n",
    "            #self.neurons_W[i] -= -alpha*self.neurons_d[i]*X\n",
    "            # W = W - dw(d, X)\n",
    "            self.neurons_W[i] -= self.dw(i, X)\n",
    "        return\n",
    "    \n",
    "    # 出力層での自分自身の誤差修正値をセット\n",
    "    def backprop_layer_output(self, O, T):\n",
    "        # d = (T - O)*dh(O)\n",
    "        self.neurons_d = (T - O)*self.dh(O)\n",
    "        return\n",
    "\n",
    "    # 前のレイヤーへの誤差修正値を算出\n",
    "    def backprop_layer(self):\n",
    "        total_prev_D = np.zeros(self.input_size)\n",
    "        for i in range(self.output_size):\n",
    "            #total_prev_D += W*d\n",
    "            total_prev_D += self.neurons_W[i]*self.neurons_d[i]\n",
    "        return total_prev_D\n",
    "\n",
    "    # 後のレイヤーで計算された誤差修正値に出力値を掛けて自レイヤーに値をセット\n",
    "    def set_layer_d(self, D, O):\n",
    "        # d = D*dh(O)\n",
    "        self.neurons_d = D*self.dh(O)\n",
    "\n",
    "    # 学習の高速化比較\n",
    "    def sgd(self, i, X):\n",
    "        # W = W - alpha*d*X\n",
    "        return -alpha*self.neurons_d[i]*X\n",
    "\n",
    "    def momentum(self, i, X):\n",
    "        # v = momentum*v - alpha*d*X\n",
    "        # W = W + v\n",
    "        momentum = 0.9\n",
    "        self.neurons_P[i] = momentum*self.neurons_P[i] - alpha*self.neurons_d[i]*X\n",
    "        return self.neurons_P[i]\n",
    "\n",
    "    def adagrad(self, i, X):\n",
    "        # h = h + (d*X)*(d*X)\n",
    "        # W = W - alpha*(1/sqrt(h))*d*X\n",
    "        self.neurons_P[i] += (self.neurons_d[i]*X)*(self.neurons_d[i]*X)\n",
    "        return -alpha*self.neurons_d[i]*X/(np.sqrt(self.neurons_P[i]) + 1e-7)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "Kkhtx2itI9gH",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "# ３層ネットワーク 784x100x10\n",
    "layer1 = Layer(784, 100)\n",
    "layer2 = Layer(100, 10)\n",
    "alpha = 0.01\n",
    "mini_batch = 100\n",
    "epoch = 0\n",
    "epochs, dpns = [], []\n",
    "\n",
    "def output_backprop_mnist(X):\n",
    "    # 正方向でニューロンの出力\n",
    "    O1 = layer1.output_layer(X)\n",
    "    Y  = layer2.output_layer(O1)\n",
    "    return Y\n",
    "\n",
    "def train_backprop_mnist(train_count):\n",
    "    global layer1, layer2, epoch, epochs, dpns\n",
    "    for count in range(train_count):\n",
    "        images, labels = mnist.train.next_batch(mini_batch)\n",
    "        square_error = 0.0\n",
    "        for i in range(mini_batch):\n",
    "            X = images[i]\n",
    "            T = labels[i]\n",
    "            # 正方向でニューロンの出力\n",
    "            O1 = layer1.output_layer(X)\n",
    "            Y  = layer2.output_layer(O1)\n",
    "            # 逆伝搬で誤差修正値をニューロン毎に算出\n",
    "            layer2.backprop_layer_output(Y, T)\n",
    "            D1 = layer2.backprop_layer()\n",
    "            layer1.set_layer_d(D1, O1)\n",
    "            # 誤差修正値を使って学習\n",
    "            layer2.train_layer(O1)\n",
    "            layer1.train_layer(X)\n",
    "            # 二乗誤差算出\n",
    "            square_error += calc_square_error(Y, T)\n",
    "        epoch += mini_batch\n",
    "        dpn = square_error/mini_batch/10 # 1ニューロンあたりの誤差\n",
    "        epochs.append(epoch)\n",
    "        dpns.append(dpn)\n",
    "    print(\"epoch:\" + str(epoch) + \" d/neuron:\" + str(dpn))\n",
    "\n",
    "train_backprop_mnist(1)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "bxYwW62VI9gJ",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "alpha = 0.01\n",
    "train_backprop_mnist(100)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "0mu2RchmI9gM",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(epochs, dpns)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "Sf7LNpS5I9gO",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "dpns_sigmoid_sgd = dpns"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "OYQAg843I9gT",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "dpns_sigmoid_momentum = dpns"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "JOs7zYRcI9gX",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "dpns_sigmoid_adagrad = dpns"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "22_r7bIhI9ga",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(epochs, dpns_sigmoid_sgd)\n",
    "plt.plot(epochs, dpns_sigmoid_momentum)\n",
    "plt.plot(epochs, dpns_sigmoid_adagrad)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "D_N6DhoDI9gd",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "多層でも学習が収束するための手法（ローカルミニマム対策）\n",
    "- PreTraining（事前学習）\n",
    "- DropOut\n",
    "- バッチ正規化"
   ]
  },
  {
   "metadata": {
    "id": "Dc6s4XKnI9gf",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "# ６層ネットワーク 784x160x80x40x20x10\n",
    "layer1 = Layer(784, 160)\n",
    "layer2 = Layer(160, 80)\n",
    "layer3 = Layer(80,  40)\n",
    "layer4 = Layer(40,  20)\n",
    "layer5 = Layer(20,  10)\n",
    "alpha = 0.01\n",
    "mini_batch = 100\n",
    "epoch = 0\n",
    "epochs, dpns = [], []\n",
    "\n",
    "def output_backprop_mnist(X):\n",
    "    # 正方向でニューロンの出力\n",
    "    O1 = layer1.output_layer(X)\n",
    "    O2 = layer2.output_layer(O1)\n",
    "    O3 = layer3.output_layer(O2)\n",
    "    O4 = layer4.output_layer(O3)\n",
    "    Y  = layer5.output_layer(O4)\n",
    "    return Y\n",
    "\n",
    "def train_backprop_mnist(train_count):\n",
    "    global layer1, layer2, layer3, layer4, layer5, epoch, epochs, dpns\n",
    "    for count in range(train_count):\n",
    "        images, labels = mnist.train.next_batch(mini_batch)\n",
    "        square_error = 0.0\n",
    "        for i in range(mini_batch):\n",
    "            X = images[i]\n",
    "            T = labels[i]\n",
    "            # 正方向でニューロンの出力\n",
    "            O1 = layer1.output_layer(X)\n",
    "            O2 = layer2.output_layer(O1)\n",
    "            O3 = layer3.output_layer(O2)\n",
    "            O4 = layer4.output_layer(O3)\n",
    "            Y  = layer5.output_layer(O4)\n",
    "            # 逆伝搬で誤差修正値をニューロン毎に算出\n",
    "            layer5.backprop_layer_output(Y, T)\n",
    "            D4 = layer5.backprop_layer()\n",
    "            layer4.set_layer_d(D4, O4)\n",
    "            D3 = layer4.backprop_layer()\n",
    "            layer3.set_layer_d(D3, O3)\n",
    "            D2 = layer3.backprop_layer()\n",
    "            layer2.set_layer_d(D2, O2)\n",
    "            D1 = layer2.backprop_layer()\n",
    "            layer1.set_layer_d(D1, O1)\n",
    "            # 誤差修正値を使って学習\n",
    "            layer5.train_layer(O4)\n",
    "            layer4.train_layer(O3)\n",
    "            layer3.train_layer(O2)\n",
    "            layer2.train_layer(O1)\n",
    "            layer1.train_layer(X)\n",
    "            # 二乗誤差算出\n",
    "            square_error += calc_square_error(Y, T)\n",
    "        epoch += mini_batch\n",
    "        dpn = square_error/mini_batch/10 # 1ニューロンあたりの誤差\n",
    "        epochs.append(epoch)\n",
    "        dpns.append(dpn)\n",
    "    print(\"epoch:\" + str(epoch) + \" d/neuron:\" + str(dpn))\n",
    "\n",
    "train_backprop_mnist(1)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "Kj4JimIBI9gg",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "train_backprop_mnist(200)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "A0b8Ph1jI9gj",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "活性化関数と重みの変更方法を変えてそれぞれ算出してグラフにしてみる"
   ]
  },
  {
   "metadata": {
    "id": "UFb5OUlLI9gl",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "dpns_6layer_sigmoid_sgd = dpns"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "RdJJuRXuI9go",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "dpns_6layer_sigmoid_momentum = dpns"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "tXLUWXHkI9gq",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "dpns_6layer_tanh_sgd = dpns"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "VKDENZa1I9gt",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "dpns_6layer_tanh_momentum = dpns"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "xFCJXc1PI9gv",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "dpns_6layer_relu_momentum = dpns"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "LYF-42p6I9gw",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(epochs, dpns_6layer_sigmoid_sgd, label=\"sigmoid_sgd\")\n",
    "plt.plot(epochs, dpns_6layer_sigmoid_momentum, label=\"sigmoid_momentum\")\n",
    "plt.plot(epochs, dpns_6layer_tanh_sgd, label=\"tanh_sgd\")\n",
    "plt.plot(epochs, dpns_6layer_tanh_momentum, label=\"tanh_momentum\")\n",
    "plt.plot(epochs, dpns_6layer_relu_momentum, label=\"relu_momentum\")\n",
    "plt.legend()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "jx2iwrY_I9gy",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "PreTraining"
   ]
  },
  {
   "metadata": {
    "id": "VpKQ21HWI9g1",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "def smaller(image):\n",
    "    def seri(x, y):\n",
    "        return y*28 + x\n",
    "\n",
    "    simages = np.zeros(14*14)\n",
    "    for i in range(14):\n",
    "        for j in range(14):\n",
    "            x, y = j*2, i*2\n",
    "            avg = (image[seri(x+0, y+0)] + image[seri(x+0, y+1)] + image[seri(x+1, y+0)] + image[seri(x+1, y+1)])/4.0\n",
    "            simages[i*14 + j] = avg\n",
    "    return simages"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "CQXi2OXgI9g3",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "# PreTraining ６層ネットワーク 784x160x80x40x20x10\n",
    "#layer1 = Layer(196, 100) # 14x14 (28x28の1/4)\n",
    "#layer2 = Layer(100, 60)\n",
    "#layer3 = Layer(60,  40)\n",
    "#layer4 = Layer(40,  20)\n",
    "#layer5 = Layer(20,  10)\n",
    "# 元に戻すためのレイヤー\n",
    "#layer1r = Layer(100, 196)\n",
    "#layer2r = Layer(60, 100)\n",
    "#layer3r = Layer(40, 60)\n",
    "#layer4r = Layer(20, 40)\n",
    "#layer5r = Layer(10, 20)\n",
    "alpha = 0.01\n",
    "mini_batch = 100\n",
    "epoch = 0\n",
    "epochs, dpns = [], []\n",
    "\n",
    "def output_pretrain_mnist(X):\n",
    "    # 正方向でニューロンの出力\n",
    "    O1 = layer1.output_layer(X)\n",
    "    O2 = layer2.output_layer(O1)\n",
    "    O3 = layer3.output_layer(O2)\n",
    "    O4 = layer4.output_layer(O3)\n",
    "    Y  = layer5.output_layer(O4)\n",
    "#    O5 = layer5.output_layer(O4)\n",
    "#    Y  = layer5r.output_layer(O5)\n",
    "    return Y\n",
    "\n",
    "def train_pretrain_mnist(train_count):\n",
    "    global layer1, layer2, layer3, layer4, layer5, epoch, epochs, dpns\n",
    "    global layer1r, layer2r, layer3r, layer4r, layer5r\n",
    "    for count in range(train_count):\n",
    "        images, labels = mnist.train.next_batch(mini_batch)\n",
    "        square_error = 0.0\n",
    "        for i in range(mini_batch):\n",
    "            X = smaller(images[i])\n",
    "            T = labels[i]\n",
    "            # 正方向でニューロンの出力\n",
    "            O1 = layer1.output_layer(X)\n",
    "            O2 = layer2.output_layer(O1)\n",
    "            O3 = layer3.output_layer(O2)\n",
    "            O4 = layer4.output_layer(O3)\n",
    "            Y  = layer5.output_layer(O4)\n",
    "            #O5 = layer5.output_layer(O4)\n",
    "            #Y  = layer5r.output_layer(O5)\n",
    "            # 逆伝搬で誤差修正値をニューロン毎に算出\n",
    "            layer5.backprop_layer_output(Y, T)\n",
    "            D4 = layer5.backprop_layer()\n",
    "            layer4.set_layer_d(D4, O4)\n",
    "            D3 = layer4.backprop_layer()\n",
    "            layer3.set_layer_d(D3, O3)\n",
    "            D2 = layer3.backprop_layer()\n",
    "            layer2.set_layer_d(D2, O2)\n",
    "            D1 = layer2.backprop_layer()\n",
    "            layer1.set_layer_d(D1, O1)\n",
    "            #layer5r.backprop_layer_output(Y, O4)\n",
    "            #D = layer5r.backprop_layer()\n",
    "            #layer5.set_layer_d(D, O5)\n",
    "            # 誤差修正値を使って学習\n",
    "            layer5.train_layer(O4)\n",
    "            layer4.train_layer(O3)\n",
    "            layer3.train_layer(O2)\n",
    "            layer2.train_layer(O1)\n",
    "            layer1.train_layer(X)\n",
    "            #layer5r.train_layer(O5)\n",
    "            #layer5.train_layer(O4)\n",
    "            # 二乗誤差算出\n",
    "            square_error += calc_square_error(Y, T)\n",
    "#            square_error += calc_square_error(Y, O4)\n",
    "        epoch += mini_batch\n",
    "        dpn = square_error/mini_batch/10 # 1ニューロンあたりの誤差\n",
    "        epochs.append(epoch)\n",
    "        dpns.append(dpn)\n",
    "        print(\"epoch:\" + str(epoch) + \" d/neuron:\" + str(dpn))\n",
    "    print(\"epoch:\" + str(epoch) + \" d/neuron:\" + str(dpn))\n",
    "\n",
    "def test_pretrain():\n",
    "    images, labels = mnist.test.next_batch(1)\n",
    "    X = smaller(images[0])\n",
    "    T = labels[0]\n",
    "    Y = output_pretrain_mnist(X)\n",
    "    # イメージ表示\n",
    "    #fig = plt.figure(figsize=(8,4))\n",
    "    fig, (figL, figR) = plt.subplots(ncols=2, figsize=(8,4))\n",
    "    figL.imshow(X.reshape((14,14)), vmin=0, vmax=1,cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    figR.imshow(Y.reshape((14,14)), vmin=0, vmax=1,cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "\n",
    "train_pretrain_mnist(1)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "bq58723bI9g6",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "train_pretrain_mnist(100)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "Qw4VOXNXI9g7",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "test_pretrain()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "sPvtrL0mI9hA",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "def test_pretrain_mnist():\n",
    "    images, labels = mnist.test.next_batch(1)\n",
    "    X = smaller(images[0])\n",
    "    T = labels[0]\n",
    "    Y = output_pretrain_mnist(X)\n",
    "    print(T)\n",
    "    print(Y)\n",
    "    print(np.argmax(Y))\n",
    "    # イメージ表示\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    plt.imshow(X.reshape((14,14)), vmin=0, vmax=1,cmap=plt.cm.gray_r, interpolation=\"nearest\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "z261AWP4I9hG",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "test_pretrain_mnist()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "LbYC3CHMI9hH",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "def test_pretrain_mnist_error():\n",
    "    test_count = 1000\n",
    "    images, labels = mnist.test.next_batch(test_count)\n",
    "    ng = 0\n",
    "    for j in range(len(images)):\n",
    "        X = smaller(images[j])\n",
    "        T = labels[j]\n",
    "        Y = output_pretrain_mnist(X)\n",
    "        if np.argmax(T) != np.argmax(Y):\n",
    "            ng += 1\n",
    "            #print(\"T:\" + str(np.argmax(T)) + \" Y:\" + str(np.argmax(Y)) + \" NG!\")\n",
    "        #else:\n",
    "            #print(\"T:\" + str(np.argmax(T)) + \" Y:\" + str(np.argmax(Y)))\n",
    "    print(ng / test_count)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "-qn3w3QbI9hL",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "test_pretrain_mnist_error()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "gd_4fkDbI9hO",
    "colab_type": "text"
   },
   "cell_type": "markdown",
   "source": [
    "XORの学習"
   ]
  },
  {
   "metadata": {
    "id": "Mn910A0fI9hO",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "data_xor    = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "teacher_xor = np.array([[0.2],  [0.8],  [0.8],  [0.2]])\n",
    "\n",
    "# ３層ネットワーク 2x4x1\n",
    "layer1 = Layer(2, 4)\n",
    "layer2 = Layer(4, 1)\n",
    "alpha = 0.05\n",
    "mini_batch = 1\n",
    "epoch = 0\n",
    "epochs, dpns = [], []\n",
    "\n",
    "\n",
    "def output_backprop_xor(X):\n",
    "    # 正方向でニューロンの出力\n",
    "    O1 = layer1.output_layer(X)\n",
    "    Y  = layer2.output_layer(O1)\n",
    "    return Y\n",
    "\n",
    "def train_backprop_xor(train_count):\n",
    "    global layer1, layer2, epoch, epochs, dpns\n",
    "    for count in range(train_count):\n",
    "        square_error = 0.0\n",
    "        for batch_i in range(mini_batch):\n",
    "            i = np.random.randint(4)\n",
    "            X = data_xor[i]\n",
    "            T = teacher_xor[i]\n",
    "            # 正方向でニューロンの出力\n",
    "            O1 = layer1.output_layer(X)\n",
    "            Y  = layer2.output_layer(O1)\n",
    "            # 逆伝搬で誤差修正値をニューロン毎に算出\n",
    "            layer2.backprop_layer_output(Y, T)\n",
    "            D1 = layer2.backprop_layer()\n",
    "            layer1.set_layer_d(D1, O1)\n",
    "            # 誤差修正値を使って学習\n",
    "            layer2.train_layer(O1)\n",
    "            layer1.train_layer(X)\n",
    "            # 二乗誤差算出\n",
    "            square_error += calc_square_error(Y, T)\n",
    "        epoch += mini_batch\n",
    "        dpn = square_error/mini_batch/1 # 1ニューロンあたりの誤差\n",
    "        epochs.append(epoch)\n",
    "        dpns.append(dpn)\n",
    "    print(\"epoch:\" + str(epoch) + \" d/neuron:\" + str(dpn))\n",
    "\n",
    "def test_backprop_xor():\n",
    "    for i in range(4):\n",
    "        X = data_xor[i]\n",
    "        T = teacher_xor[i]\n",
    "        Y = output_backprop_xor(X)\n",
    "        print(\"X:\" + str(X) + \" Y:\" + str(Y) + \" T:\" + str(T))\n",
    "\n",
    "train_backprop_xor(1)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "411qu3snI9hQ",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "train_backprop_xor(1000)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "metadata": {
    "id": "5CcJSE-cI9hR",
    "colab_type": "code",
    "colab": {}
   },
   "cell_type": "code",
   "source": [
    "test_backprop_xor()"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}
